{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the same code as before, please solve the following exercises\n",
    "    1. Change the number of observations to 100,000 and see what happens.\n",
    "\n",
    "Useful tip: When you change something, don't forget to RERUN all cells. This can be done easily by clicking:\n",
    "Kernel -> Restart & Run All\n",
    "\n",
    "If you don't do that, your algorithm may keep the OLD values of all parameters.\n",
    "\n",
    "## Solution\n",
    "\n",
    "Find the variable \"observations\" and change it to 100000, instead of 1000.\n",
    "\n",
    "Here are some takeaways:\n",
    "1. It takes the algorithm more time to solve the problem.\n",
    "2. No further adjustments are needed, as all the code is written irrespeective of the number of observations\n",
    "3. The result is the same as we the loss was scaled (the mean_squared_loss, so the average L2-norm).\n",
    "4. The loss starts oscillating at some point.\n",
    "4. matplotlib may not be able to plot the data, as there are too many points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We must always import the relevant libraries for our problem at hand. NumPy and TensorFlow are required for this example.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "We generate data using the exact same logic and code as the example from the previous notebook. The only difference now is that we save it to an npz file. Npz is numpy's file type which allows you to save numpy arrays into a single .npz file. We introduce this change because in machine learning most often: \n",
    "\n",
    "* you are given some data (csv, database, etc.)\n",
    "* you preprocess it into a desired format (later on we will see methods for preprocesing)\n",
    "* you save it into npz files (if you're working in Python) to access later\n",
    "\n",
    "Nothing to worry about - this is literally saving your NumPy arrays into a file that you can later access, nothing more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we should declare a variable containing the size of the training set we want to generate.\n",
    "observations = 100000\n",
    "\n",
    "# We will work with two variables as inputs. You can think about them as x1 and x2 in our previous examples.\n",
    "# We have picked x and z, since it is easier to differentiate them.\n",
    "# We generate them randomly, drawing from an uniform distribution. There are 3 arguments of this method (low, high, size).\n",
    "# The size of xs and zs is observations x 1. In this case: 1000 x 1.\n",
    "xs = np.random.uniform(low=-10, high=10, size=(observations,1))\n",
    "zs = np.random.uniform(-10, 10, (observations,1))\n",
    "\n",
    "# Combine the two dimensions of the input into one input matrix. \n",
    "# This is the X matrix from the linear model y = x*w + b.\n",
    "# column_stack is a Numpy method, which combines two matrices (vectors) into one.\n",
    "generated_inputs = np.column_stack((xs,zs))\n",
    "\n",
    "# We add a random small noise to the function i.e. f(x,z) = 2x - 3z + 5 + <small noise>\n",
    "noise = np.random.uniform(-1, 1, (observations,1))\n",
    "\n",
    "# Produce the targets according to our f(x,z) = 2x - 3z + 5 + noise definition.\n",
    "# In this way, we are basically saying: the weights should be 2 and -3, while the bias is 5.\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "# save into an npz file called \"TF_intro\"\n",
    "np.savez('TF_intro', inputs=generated_inputs, targets=generated_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving with TensorFlow\n",
    "\n",
    "<i/>Note: This intro is just the basics of TensorFlow which has way more capabilities and depth than that.<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from the NPZ\n",
    "training_data = np.load('TF_intro.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "3125/3125 - 2s - loss: 0.7280 - 2s/epoch - 714us/step\n",
      "Epoch 2/100\n",
      "3125/3125 - 2s - loss: 0.3798 - 2s/epoch - 599us/step\n",
      "Epoch 3/100\n",
      "3125/3125 - 2s - loss: 0.3775 - 2s/epoch - 634us/step\n",
      "Epoch 4/100\n",
      "3125/3125 - 2s - loss: 0.3802 - 2s/epoch - 649us/step\n",
      "Epoch 5/100\n",
      "3125/3125 - 2s - loss: 0.3808 - 2s/epoch - 604us/step\n",
      "Epoch 6/100\n",
      "3125/3125 - 2s - loss: 0.3812 - 2s/epoch - 592us/step\n",
      "Epoch 7/100\n",
      "3125/3125 - 2s - loss: 0.3812 - 2s/epoch - 619us/step\n",
      "Epoch 8/100\n",
      "3125/3125 - 2s - loss: 0.3795 - 2s/epoch - 622us/step\n",
      "Epoch 9/100\n",
      "3125/3125 - 2s - loss: 0.3780 - 2s/epoch - 624us/step\n",
      "Epoch 10/100\n",
      "3125/3125 - 2s - loss: 0.3794 - 2s/epoch - 614us/step\n",
      "Epoch 11/100\n",
      "3125/3125 - 2s - loss: 0.3818 - 2s/epoch - 659us/step\n",
      "Epoch 12/100\n",
      "3125/3125 - 2s - loss: 0.3777 - 2s/epoch - 638us/step\n",
      "Epoch 13/100\n",
      "3125/3125 - 2s - loss: 0.3809 - 2s/epoch - 705us/step\n",
      "Epoch 14/100\n",
      "3125/3125 - 2s - loss: 0.3767 - 2s/epoch - 590us/step\n",
      "Epoch 15/100\n",
      "3125/3125 - 2s - loss: 0.3803 - 2s/epoch - 660us/step\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 35\u001b[0m\n\u001b[0;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mcustom_optimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# finally we fit the model, indicating the inputs and targets\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# if they are not otherwise specified the number of epochs will be 1 (a single epoch of training), \u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# so the number of epochs is 'kind of' mandatory, too\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# we can play around with verbose; we prefer verbose=2\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtargets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\keras\\src\\engine\\training.py:1798\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1796\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1798\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1801\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_r\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1805\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1806\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1411\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1411\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1412\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1413\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1416\u001b[0m )\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:689\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    690\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    691\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:839\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \n\u001b[0;32m    832\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 839\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:818\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    821\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    822\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    823\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    824\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    825\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    826\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:808\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    807\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 808\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\giovanni.cintra\\Documents\\venv\\py311-TF2.15\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:535\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    534\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 535\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    538\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Declare a variable where we will store the input size of our model\n",
    "# It should be equal to the number of variables you have\n",
    "input_size = 2\n",
    "# Declare the output size of the model\n",
    "# It should be equal to the number of outputs you've got (for regressions that's usually 1)\n",
    "output_size = 1\n",
    "\n",
    "# Outline the model\n",
    "# We lay out the model in 'Sequential'\n",
    "# Note that there are no calculations involved - we are just describing our network\n",
    "model = tf.keras.Sequential([\n",
    "                            # Each 'layer' is listed here\n",
    "                            # The method 'Dense' indicates, our mathematical operation to be (xw + b)\n",
    "                            tf.keras.layers.Dense(output_size,\n",
    "                                                 # there are extra arguments you can include to customize your model\n",
    "                                                 # in our case we are just trying to create a solution that is \n",
    "                                                 # as close as possible to our NumPy model\n",
    "                                                 kernel_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1),\n",
    "                                                 bias_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1)\n",
    "                                                 )\n",
    "                            ])\n",
    "\n",
    "# We can also define a custom optimizer, where we can specify the learning rate\n",
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
    "# Note that sometimes you may also need a custom loss function \n",
    "# That's much harder to implement and won't be covered in this course though\n",
    "\n",
    "# 'compile' is the place where you select and indicate the optimizers and the loss\n",
    "model.compile(optimizer=custom_optimizer, loss='mean_squared_error')\n",
    "\n",
    "# finally we fit the model, indicating the inputs and targets\n",
    "# if they are not otherwise specified the number of epochs will be 1 (a single epoch of training), \n",
    "# so the number of epochs is 'kind of' mandatory, too\n",
    "# we can play around with verbose; we prefer verbose=2\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the weights and bias\n",
    "Extracting the weight(s) and bias(es) of a model is not an essential step for the machine learning process. In fact, usually they would not tell us much in a deep learning context. However, this simple example was set up in a way, which allows us to verify if the answers we get are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.9821367],\n",
       "        [-2.9964035]], dtype=float32), array([5.0029154], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the weights and biases is achieved quite easily\n",
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.9821367],\n",
       "       [-2.9964035]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can save the weights and biases in separate variables for easier examination\n",
    "# Note that there can be hundreds or thousands of them!\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.0029154], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can save the weights and biases in separate variables for easier examination\n",
    "# Note that there can be hundreds or thousands of them!\n",
    "bias = model.layers[0].get_weights()[1]\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the outputs (make predictions)\n",
    "Once more, this is not an essential step, however, we usually want to be able to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.4],\n",
       "       [  7.5],\n",
       "       [ 31.6],\n",
       "       ...,\n",
       "       [-19.2],\n",
       "       [ 34.1],\n",
       "       [ 21.4]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can predict new values in order to actually make use of the model\n",
    "# Sometimes it is useful to round the values to be able to read the output\n",
    "# Usually we use this method on NEW DATA, rather than our original training data\n",
    "model.predict_on_batch(training_data['inputs']).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.7],\n",
       "       [  7.1],\n",
       "       [ 32.6],\n",
       "       ...,\n",
       "       [-19.4],\n",
       "       [ 34.2],\n",
       "       [ 22.1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we display our targets (actual observed values), we can manually compare the outputs and the targets\n",
    "training_data['targets'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The model is optimized, so the outputs are calculated based on the last form of the model\n",
    "\n",
    "# We have to np.squeeze the arrays in order to fit them to what the plot function expects.\n",
    "# Doesn't change anything as we cut dimensions of size 1 - just a technicality.\n",
    "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data['targets']))\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()\n",
    "\n",
    "# Voila - what you see should be exactly the same as in the previous notebook!\n",
    "# You probably don't see the point of TensorFlow now - it took us the same number of lines of code\n",
    "# to achieve this simple result. However, once we go deeper in the next chapter,\n",
    "# TensorFlow will save us hundreds of lines of code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-TF2.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
